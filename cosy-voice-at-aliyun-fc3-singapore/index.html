<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jimmy TTS Demo</title>
    <!-- Import Element Plus CSS -->
    <link rel="stylesheet" href="https://unpkg.com/element-plus/dist/index.css">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f7fa;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .audio-container {
            margin-top: 20px;
        }
        .chunk-item {
            margin: 10px 0;
            padding: 10px;
            background-color: #fff;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .status-indicator {
            margin-top: 20px;
            text-align: center;
        }
    </style>
</head>
<body>
    <div id="app">
        <div class="container">
            <div class="header">
                <h1>Jimmy TTS Demo</h1>
            </div>
            
            <el-form @submit.prevent="generateSpeech">
                <el-form-item>
                    <el-input
                        v-model="inputText"
                        type="textarea"
                        :rows="4"
                        :placeholder="'请输入要转换的文字...'"
                        :disabled="isGenerating"
                    ></el-input>
                </el-form-item>
                
                <el-form-item>
                    <el-button 
                        type="primary" 
                        @click="generateSpeech" 
                        :loading="isGenerating"
                        :disabled="!inputText || isGenerating"
                    >
                        {{ isGenerating ? '生成中...' : '生成语音' }}
                    </el-button>
                    <el-button 
                        @click="clearAll" 
                        :disabled="isGenerating || audioChunks.length === 0"
                    >
                        清除所有
                    </el-button>
                    <el-button
                        type="success"
                        @click="generateRandomSentence"
                        :disabled="isGenerating"
                    >
                        生成句子
                    </el-button>
                </el-form-item>
            </el-form>

            <div class="status-indicator" v-if="isGenerating">
                <div style="margin-bottom: 10px;">TTS生成中...</div>
                <el-progress type="circle" :percentage="generationProgress"></el-progress>
            </div>

            <div class="audio-container" v-if="audioChunks.length > 0">
                <h3>完整音频（合成后）：</h3>
                <audio :src="combinedAudioUrl" controls v-if="combinedAudioUrl"></audio>
            </div>

            <div class="audio-container" v-if="audioChunks.length > 0">
                <h3>生成的音频流片段:</h3>
                <div class="chunk-item" v-for="chunk in audioChunks" :key="chunk.id">
                    <div>片段 #{{ chunk.id + 1 }}</div>
                    <audio :src="chunk.audioUrl" controls></audio>
                </div>
            </div>
        </div>
    </div>

    <!-- Import Vue 3 -->
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <!-- Import Element Plus -->
    <script src="https://unpkg.com/element-plus"></script>
    <!-- Import Element Plus Icons -->
    <script src="https://unpkg.com/@element-plus/icons-vue"></script>
    
    <script>
        const { createApp, ref } = Vue;
        const { ElMessage } = ElementPlus;

        const app = createApp({
            setup() {
                const inputText = ref('');
                const isGenerating = ref(false);
                const audioChunks = ref([]);
                const generationProgress = ref(0);
                const currentChunkIndex = ref(0);
                const combinedAudioPlayer = ref(null);
                const combinedAudioUrl = ref(null);
                let ws = null;

                const sentences = [
                    "今天天气晴朗，阳光照耀着大地，让人心情愉悦。",
                    "我最近开始学习烹饪，尝试做一些新的菜肴，感觉很有成就感。",
                    "昨晚我和朋友们一起聚会，聊了很多有趣的事情，笑声不断。",
                    "每当我听到那首歌，就会想起我们一起度过的美好时光。",
                    "最近我迷上了摄影，喜欢用相机记录生活中的点滴瞬间。",
                    "这个周末我们打算去爬山，享受大自然的美丽风景。",
                    "有时候我会在公园里散步，享受清新的空气和宁静的环境。",
                    "我们家附近新开了一家咖啡馆，环境很好，非常适合放松心情。",
                    "昨天我参加了一个有趣的讲座，学到了很多新的知识和见解。",
                    "最近我在看一本关于心理学的书，觉得非常有趣且启发性强。",
                    "每天早上我都会喝一杯咖啡，帮助我提神醒脑，开始新的一天。",
                    "我们计划下个月去海边度假，希望能享受阳光和沙滩的乐趣。",
                    "有时候我会在晚上写日记，把一天的感受和想法记录下来。",
                    "最近我开始练习瑜伽，感觉身心都得到了很好的放松和舒缓。",
                    "昨天我在网上看到一个很有趣的纪录片，立刻就被吸引住了。",
                    "这个冬天特别寒冷，希望能早点迎来温暖的春天。",
                    "我们计划去参加一个音乐节，希望能听到喜欢的乐队现场演出。",
                    "有时候我会在晚上看星星，思考人生中的种种可能性和梦想。",
                    "最近我在尝试写作，希望能把自己的故事分享给更多的人。",
                    "昨晚我做了一个奇怪的梦，醒来后还在思考它的含义是什么。"
                ];

                const generateRandomSentence = () => {
                    const randomIndex = Math.floor(Math.random() * sentences.length);
                    inputText.value = sentences[randomIndex];
                };

                const generateSpeech = () => {
                    if (!inputText.value || isGenerating.value) return;
                    
                    isGenerating.value = true;
                    audioChunks.value = [];
                    generationProgress.value = 0;

                    // Updated WebSocket URL with port 50000
                    ws = new WebSocket('ws://tts.watchfun-intelligence.com:50000/tts');

                    ws.onopen = () => {
                        ws.send(inputText.value);
                    };

                    ws.onmessage = (event) => {
                        const data = JSON.parse(event.data);
                        
                        if (data.error) {
                            ElMessage.error('Error: ' + data.error);
                            isGenerating.value = false;
                            return;
                        }

                        // Create audio URL from base64 data
                        const audioBlob = base64ToBlob(data.audio_data, 'audio/wav');
                        const audioUrl = URL.createObjectURL(audioBlob);
                        
                        // Add to audio chunks
                        audioChunks.value.push({
                            id: data.chunk_id,
                            audioUrl: audioUrl
                        });

                        // Update progress (assuming approximately 10 chunks total)
                        generationProgress.value = Math.min(Math.round((data.chunk_id + 1) * 10), 100);
                    };

                    ws.onclose = () => {
                        isGenerating.value = false;
                        generationProgress.value = 100;
                        combineAudioChunks(); // Combine the chunks when generation is complete
                    };

                    ws.onerror = (error) => {
                        ElMessage.error('WebSocket error occurred');
                        isGenerating.value = false;
                    };
                };

                const playNextChunk = () => {
                    if (currentChunkIndex.value < audioChunks.value.length - 1) {
                        currentChunkIndex.value++;
                        // Need to manually load and play the next chunk
                        combinedAudioPlayer.value.load();
                        // Add a small delay before playing to ensure the audio is loaded
                        setTimeout(() => {
                            const playPromise = combinedAudioPlayer.value.play();
                            if (playPromise !== undefined) {
                                playPromise.catch(error => {
                                    console.log("Auto-play prevented:", error);
                                });
                            }
                        }, 100);
                    } else {
                        currentChunkIndex.value = 0; // Reset to beginning when all chunks are played
                    }
                };

                const clearAll = () => {
                    audioChunks.value.forEach(chunk => {
                        URL.revokeObjectURL(chunk.audioUrl);
                    });
                    if (combinedAudioUrl.value) {
                        URL.revokeObjectURL(combinedAudioUrl.value);
                        combinedAudioUrl.value = null;
                    }
                    audioChunks.value = [];
                    generationProgress.value = 0;
                };

                const base64ToBlob = (base64, type) => {
                    const binStr = atob(base64);
                    const len = binStr.length;
                    const arr = new Uint8Array(len);
                    for (let i = 0; i < len; i++) {
                        arr[i] = binStr.charCodeAt(i);
                    }
                    return new Blob([arr], { type: type });
                };

                const concatenateAudioBuffers = async (audioContext, audioBuffers) => {
                    const totalLength = audioBuffers.reduce((sum, buffer) => sum + buffer.length, 0);
                    const combinedBuffer = audioContext.createBuffer(
                        1, // mono
                        totalLength,
                        audioBuffers[0].sampleRate
                    );
                    const channelData = combinedBuffer.getChannelData(0);
                    
                    let offset = 0;
                    audioBuffers.forEach(buffer => {
                        channelData.set(buffer.getChannelData(0), offset);
                        offset += buffer.length;
                    });
                    
                    return combinedBuffer;
                };

                const combineAudioChunks = async () => {
                    if (audioChunks.value.length === 0) return;

                    try {
                        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        
                        // Convert all chunks to AudioBuffers
                        const bufferPromises = audioChunks.value.map(async chunk => {
                            const response = await fetch(chunk.audioUrl);
                            const arrayBuffer = await response.arrayBuffer();
                            return await audioContext.decodeAudioData(arrayBuffer);
                        });

                        const audioBuffers = await Promise.all(bufferPromises);
                        const combinedBuffer = await concatenateAudioBuffers(audioContext, audioBuffers);

                        // Convert the combined buffer back to WAV format
                        const wavData = audioBufferToWav(combinedBuffer);
                        const blob = new Blob([wavData], { type: 'audio/wav' });
                        
                        // Clean up previous URL if it exists
                        if (combinedAudioUrl.value) {
                            URL.revokeObjectURL(combinedAudioUrl.value);
                        }
                        
                        combinedAudioUrl.value = URL.createObjectURL(blob);
                    } catch (error) {
                        console.error('Error combining audio chunks:', error);
                    }
                };

                const audioBufferToWav = (buffer) => {
                    const numChannels = 1;
                    const sampleRate = buffer.sampleRate;
                    const format = 1; // PCM
                    const bitDepth = 16;
                    
                    const bytesPerSample = bitDepth / 8;
                    const blockAlign = numChannels * bytesPerSample;
                    
                    const wav = new ArrayBuffer(44 + buffer.length * bytesPerSample);
                    const view = new DataView(wav);
                    
                    // Write WAV header
                    const writeString = (view, offset, string) => {
                        for (let i = 0; i < string.length; i++) {
                            view.setUint8(offset + i, string.charCodeAt(i));
                        }
                    };
                    
                    writeString(view, 0, 'RIFF');
                    view.setUint32(4, 36 + buffer.length * bytesPerSample, true);
                    writeString(view, 8, 'WAVE');
                    writeString(view, 12, 'fmt ');
                    view.setUint32(16, 16, true);
                    view.setUint16(20, format, true);
                    view.setUint16(22, numChannels, true);
                    view.setUint32(24, sampleRate, true);
                    view.setUint32(28, sampleRate * blockAlign, true);
                    view.setUint16(32, blockAlign, true);
                    view.setUint16(34, bitDepth, true);
                    writeString(view, 36, 'data');
                    view.setUint32(40, buffer.length * bytesPerSample, true);
                    
                    // Write audio data
                    const samples = buffer.getChannelData(0);
                    let offset = 44;
                    for (let i = 0; i < samples.length; i++) {
                        const sample = Math.max(-1, Math.min(1, samples[i]));
                        view.setInt16(offset, sample * 0x7FFF, true);
                        offset += 2;
                    }
                    
                    return new Uint8Array(wav);
                };

                return {
                    inputText,
                    isGenerating,
                    audioChunks,
                    generationProgress,
                    generateSpeech,
                    clearAll,
                    generateRandomSentence,
                    currentChunkIndex,
                    playNextChunk,
                    combinedAudioPlayer,
                    combinedAudioUrl
                };
            }
        });

        app.use(ElementPlus);
        app.mount('#app');
    </script>
</body>
</html> 